@book{Sutton:1998:IRL:551283,
	author = {Sutton, Richard S. and Barto, Andrew G.},
	title = {Introduction to Reinforcement Learning},
	year = {1998},
	isbn = {0262193981},
	edition = {1st},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
} 

@book{Sutton,
 author = {Sutton, Richard S. and Barto, Andrew G.},
 title = {Introduction to Reinforcement Learning},
 year = {2016},
 edition = {{Draft, 2nd}},
 url = {http://ufal.mff.cuni.cz/~straka/courses/npfl114/2016/sutton-bookdraft2016sep.pdf}
}

%Asynchronous Methods for Deep Reinforcement Learning
@article{DBLP:journals/corr/MnihBMGLHSK16,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  timestamp = {Tue, 01 Mar 2016 17:47:25 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihBMGLHSK16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

%Playing Atari with Deep Reinforcement Learning
@article{DBLP:journals/corr/MnihKSGAWR13,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  timestamp = {Wed, 01 Apr 2015 20:06:15 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihKSGAWR13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

%Temporal Difference Learning and TD-Gammon
@article{Tesauro:1995:TDL:203330.203343,
 author = {Tesauro, Gerald},
 title = {Temporal Difference Learning and TD-Gammon},
 journal = {Commun. ACM},
 issue_date = {March 1995},
 volume = {38},
 number = {3},
 month = mar,
 year = {1995},
 issn = {0001-0782},
 pages = {58--68},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/203330.203343},
 doi = {10.1145/203330.203343},
 acmid = {203343},
 publisher = {ACM},
 address = {New York, NY, USA},
}
%Mastering the Game of {Go} with Deep Neural Networks and Tree Search
@article{Silver_2016,
  added-at = {2016-03-11T14:36:05.000+0100},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/ytyoun},
  doi = {10.1038/nature16961},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  journal = {Nature},
  keywords = {baduk go google},
  month = jan,
  number = 7587,
  pages = {484--489},
  publisher = {Nature Publishing Group},
  timestamp = {2016-03-11T14:37:40.000+0100},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  volume = 529,
  year = 2016
}

%Deep Reinforcement Learning framework for Autonomous Driving
@article {Sallab:2017:2470-1173:70,
author = "Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil",
title = "Deep Reinforcement Learning framework for Autonomous Driving",
journal = "Electronic Imaging",
volume = "2017",
number = "19",
year = "2017",
publication date ="2017-01-29T00:00:00",
pages = "70-76",
itemtype = "ARTICLE",
parent_itemid = "infobike://ist/ei",
issn = "2470-1173",
publishercode ="ist",
url = "http://www.ingentaconnect.com/content/ist/ei/2017/00002017/00000019/art00012",
doi = "doi:10.2352/ISSN.2470-1173.2017.19.AVM-023",
keyword = "REINFORCEMENT LEARNING, DEEP LEARNING, AUTONOMOUS DRIVING"
}

%DQN theory
@misc {DQN_theory,
	author = {Tambet Matiisen},
  	title = {Demystifying Deep Reinforcement Learning},
  	howpublished = {\url{https://www.nervanasys.com/demystifying-deep-reinforcement-learning/}},
  	note = {Accessed: 12-05-17}
}

%DQN Flappy bird
@misc {DQN_Flappy,
	author = {Ben Lau},
  	title = {Using Keras and Deep Q-Network to Play FlappyBird},
  	howpublished = {\url{https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html}},
  	note = {Accessed: 12-05-17}
}

%Continuous control with DRL
@article{DBLP:journals/corr/LillicrapHPHETS15,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  journal   = {CoRR},
  volume    = {abs/1509.02971},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.02971},
  timestamp = {Thu, 01 Oct 2015 14:28:48 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/LillicrapHPHETS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

%DDPG with torcs
@misc {DDPG_Torcs,
	author = {Ben Lau},
  	title = {Using Keras and Deep Deterministic Policy Gradient to play TORCS},
 	howpublished = {\url{https://yanpanlau.github.io/2016/10/11/Torcs-Keras.html}},
  	note = {Accessed: 16-05-17}
}

%DPG algorithm
@inproceedings{DBLP:conf/icml/SilverLHDWR14,
  author    = {David Silver and
               Guy Lever and
               Nicolas Heess and
               Thomas Degris and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Deterministic Policy Gradient Algorithms},
  booktitle = {Proceedings of the 31th International Conference on Machine Learning,
               {ICML} 2014, Beijing, China, 21-26 June 2014},
  pages     = {387--395},
  year      = {2014},
  crossref  = {DBLP:conf/icml/2014},
  url       = {http://jmlr.org/proceedings/papers/v32/silver14.html},
  timestamp = {Wed, 29 Mar 2017 16:45:25 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icml/SilverLHDWR14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

%Sensor input from torcs
@misc {Data_from_Torcs,
	author = {Bernhard Wymann and Eric Espié},
	title = {Data from TORCS},
  	howpublished = {\url{http://xed.ch/help/torcs.html}},
  	note = {Accessed: 16-05-17}
}

%A3C Doom
@misc {A3CDoom,
	author = {Arthur Juliani},
	title = {Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)},
	howpublished = {\url{https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2}},
	note = {Accessed: 17-05-17}
}

%CIFAR 10 Data set
@misc {CIFAR_10,
	author = {Alex Krizhevsky},
  	title = {The CIFAR-10 dataset},
  	howpublished = {\url{https://www.cs.toronto.edu/~kriz/cifar.html}},
  	note = {Accessed: 22-05-17}
}

%Convolutional Neural Networks for Visual Recognitiont
@misc {CNN_course,
	author = {Andrej Karpathy},
  	title = {Convolutional Neural Networks for Visual Recognition},
  	howpublished = {\url{http://cs231n.github.io/convolutional-networks/}},
  	note = {Accessed: 22-05-17}
}

%An Intuitive Explanation of Convolutional Neural Networks
@misc {Fully_Connected_Layer,
	author = {Ujjwal Karn},
 	title = {An Intuitive Explanation of Convolutional Neural Networks},
  	howpublished = {\url{https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/}},
  	note = {Accessed: 22-05-17}
}

%RNN video
@misc {RNNvideo,
	author = {DeepLearning.TV},
	title = {Recurrent Neural Networks - Ep. 9 (Deep Learning SIMPLIFIED)},
	howpublished = {\url{https://www.youtube.com/watch?v=_aCuOwF1ZjU}},
	note = {Accessed: 22-05-17}
}

%NeonRNN
@misc {NeonRNN,
	author = {Nervana},
	title = {(2) Recurrent Neural Networks},
	howpublished = {\url{https://www.youtube.com/watch?v=Ukgii7Yd_cU}},
	note = {Accessed: 22-05-17}
}


%RMSProp
@misc {RMSProp,
	author = {Wikipedia},
	title = {RMSProp},
	howpublished = {\url{https://en.wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp}},
	note = {Accessed: 24-05-17}
}

%Optimizers
@misc {Optimizers,
	author = {Quora},
	title = {What are differences between update rules like AdaDelta, RMSProp, AdaGrad and AdaM?},
	howpublished = {\url{https://www.quora.com/What-are-differences-between-update-rules-like-AdaDelta-RMSProp-AdaGrad-and-AdaM}},
	note = {Accessed: 24-05-17}
}

%Torcs website
@misc {TORCS_website,
	author = {Bernhard Wymann and Eric Espié},
  	title = {TORCS official website},
 	howpublished = {\url{http://torcs.sourceforge.net/}},
  	note = {Accessed: 24-05-17}
}


%Open Ai website
@misc {OPENAI_website,
	author = {OpenAI},
  	title = {OpenAI Gym website},
 	howpublished = {\url{https://gym.openai.com/}},
  	note = {Accessed: 24-05-17}
}

%Gym-TORCSwebsite
@misc {Gym_TORCS_website,
	author = {Naoto Yoshida},
 	title = {Gym-TORCS website},
  	howpublished = {\url{https://github.com/ugo-nama-kun/gym_torcs}},
  	note = {Accessed: 24-05-17}
}

%A3CLoss
@misc {A3CLoss,
	author = {Quim Llimona},
	title = {TensorFlow implementation of an Advantage Actor-Critic loss},
	howpublished = {\url{https://gist.github.com/lemonzi/7910d7202deb6660f80cf3917a1dab0d}},
	note = {Accessed: 26-05-17}
}

%A3CImplementation
@misc {A3CImplementation,
	author = {Morvan Zhou},
	title = {A3C continuous action},
	howpublished = {\url{https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/10_A3C/A3C_continuous_action.py}},
	note = {Accessed: 29-05-17}
}



%Reward small explanation
@misc {reward_small,
	author = {Kevin Murphy},
	title = {A brief introduction to reinforcement learning},
	howpublished = {\url{http://www.cs.ubc.ca/~murphyk/Bayes/pomdp.html}},
	note = {Accessed: 01-06-17}
}

%Publications of DeepMind in reinforcement learning
@misc {Publications_Deepmind,
	author = {DeepMind},
	title = {Publications of DeepMind in reinforcement learning},
	howpublished = {\url{https://deepmind.com/research/publications/?author=D+Silver}},
	note = {Accessed: 01-06-17}
}

%DDQN
@article{DBLP:journals/corr/HasseltGS15,
  author    = {Hado van Hasselt and
               Arthur Guez and
               David Silver},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  timestamp = {Thu, 01 Oct 2015 14:28:48 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HasseltGS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

%Evolution Strategies as a Scalable Alternative to Reinforcement Learning
@article{EvolStrat,
	author    = {Tim Salimans and 
	Jonathan Ho and
	Xi Chen and
	Ilya Sutskever},
	title     = {Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
	journal   = {arXiv:1703.03864},
	year      = {2017},
	url       = {https://arxiv.org/abs/1703.03864}
}

