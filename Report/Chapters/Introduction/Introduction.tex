\chapter{Introduction}\label{Introduction}
With the advances in the computational power of processors, new opportunities for growth opened up in the world. A lot of algorithms that are well known for decades couldn't be tested because powerful computational possibilities were not available at the time of their invention. Nowadays this is not a problem anymore. The expansion in computational power impacted the bloom of a very impressive domain as artificial intelligence that, not long ago, has been only a product of science fiction movies. The different machine learning algorithms that were once just mathematical models are now implemented in real world applications that make wonders. This rapidly growing field has already made a big difference in people's everyday lives through applications like Google assistant and Google self-driving car - Waymo.

Among the various paradigms in machine learning, a very notable one is reinforcement learning, which has been especially paid attention to in the most recent years and proven to make incredible results. Reinforcement learning is a known field in cognitive science that focuses on the study of the thinking processes. The main idea is that learning happens with the help of a feedback coming from the outer world and this exact idea is resembled in the reinforcement learning algorithms. 

In psychology, the idea of trial-and-error has been expressed by Edward Thorndike in 1911 \cite{Sutton:1998:IRL:551283}. So, this very idea existed for a long time until it could become the basis of a machine learning paradigm. Actually, the thought about applying it to computers came to life as soon as the thought of computers appeared in the Turing period, in 1950 \cite{Sutton:1998:IRL:551283}. In its development it was first mixed up with supervised learning, so that later after the 70s to become more and more refined. Amidst the most representative books is the one written by Richard S. Sutton and Andrew G. Barto called "Introduction to Reinforcement Learning" \cite{Sutton:1998:IRL:551283} originally published in 1998. The book \cite{Sutton:1998:IRL:551283} provides a strong theoretical foundation and it's currently being worked on for a second edition \cite{Sutton}.

Lately, DeepMind made important contributions in artificial intelligence by also using reinforcement learning algorithms together with deep learning techniques in neural networks. They have produced some state-of-the-art papers that became truly meaningful for the technological advancement nowadays. These include the papers "Playing Atari with Deep Reinforcement Learning" \cite{DBLP:journals/corr/MnihKSGAWR13} - 2013, where deep Q-learning is used, and the biggest most recent breakthrough, "Mastering the Game of Go with Deep Neural Networks and Tree Search" \cite{Silver_2016} - 2016, where the reinforcement learning Monte Carlo tree search is used with Q-learning. Also, in June 2016, they published a paper "Asynchronous Methods for Deep Reinforcement Learning" \cite{DBLP:journals/corr/MnihBMGLHSK16} that provides a clear comparison of the different deep reinforcement learning algorithms for the asynchronous training and emphasizing an algorithm - "Asynchronous Advantage Actor-Critic" that surpasses the Atari performances.

In the abundant flow of discoveries in artificial intelligence and deep reinforcement learning, the reuse of the new techniques and their further exploration was imminent. This has also been the case of this project, which formed the actual goal of the thesis. More exactly, the goal is to dive deep into the reinforcement learning paradigm. The scope of the thesis is to gain knowledge in reinforcement learning, research the most recent development in the area, try out different algorithms, and find ways for improvement. As a very suitable environment for experimenting and getting the data easier presents itself to be the open racing car simulator (TORCS) in the sense of the driver-less cars or autonomous driving principle. Putting it all together, the deliverables of the thesis are the project's documentation in a thoroughly structured report that would present all the achievements and the running program with the implemented algorithms. These can all be found at the following link: https://github.com/popovicidaniela/Master-Thesis.

As a consequence, the structure of the thesis report was planned so that it would resemble the earlier defined scope. Therefore, the report starts with a theoretical background chapter for expanding the knowledge base about reinforcement learning, about previous research in this scientific area and general artificial neural networks. The next chapter emphasizes the methods, algorithms and neural networks architectures that were studied and tried out in order to reach the formation of the advantage actor-critic implementation in TORCS. Further, the results of different experiments are presented. The thesis report continues with a discussion chapter where the results are explained and improvement ideas are developed. The last chapter represents the conclusion of the project and ends the thesis report.